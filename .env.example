# ════════════════════════════════════════════════════════════════════════════
# SambungChat Environment Configuration Example
# ════════════════════════════════════════════════════════════════════════════
#
# Copy this file to .env and fill in your actual values.
# DO NOT commit the .env file to version control.
#
# Required Steps:
# 1. Copy this file: cp .env.example .env
# 2. Fill in the required values below (marked with [REQUIRED])
# 3. Choose at least ONE AI provider and configure its API key
#
# Usage:
# - Local development: bun run dev
# - Docker development: docker compose up
# - Docker production: docker compose -f docker-compose.prod.yml up
#
# ════════════════════════════════════════════════════════════════════════════

# ════════════════════════════════════════════════════════════════════════════
# CORE APPLICATION SETTINGS
# ════════════════════════════════════════════════════════════════════════════

# Node environment (development, production, or test)
NODE_ENV=development

# Server port (for local development)
SERVER_PORT=3000

# Web port (for local development)
WEB_PORT=5173

# Public Server URL (used by Better Auth client on frontend)
# This should point to the frontend URL where the user is
PUBLIC_SERVER_URL=http://localhost:5173

# Public API URL (backend API URL - used for fetch calls from frontend)
PUBLIC_API_URL=http://localhost:3000

# ════════════════════════════════════════════════════════════════════════════
# DATABASE CONFIGURATION
# ════════════════════════════════════════════════════════════════════════════

# PostgreSQL database connection string [REQUIRED]
# Format: postgresql://user:password@host:port/database
# Local development: postgresql://postgres:password@localhost:5432/sambung-chat
# Docker: postgresql://postgres:password@postgres:5432/sambung-chat (use postgres service name)
DATABASE_URL=postgresql://postgres:password@localhost:5432/sambung-chat

# Docker PostgreSQL Configuration (used by docker-compose.yml)
POSTGRES_USER=sambungchat
POSTGRES_PASSWORD=sambungchat_dev
POSTGRES_DB=sambungchat_dev

# ════════════════════════════════════════════════════════════════════════════
# AUTHENTICATION CONFIGURATION
# ════════════════════════════════════════════════════════════════════════════

# Better-Auth secret key [REQUIRED]
# Must be at least 32 characters long
# Generate a secure secret: openssl rand -base64 32
BETTER_AUTH_SECRET=your-better-auth-secret-at-least-32-characters-long

# Better-Auth URL [REQUIRED]
# The URL where your backend server is running (for OAuth callbacks)
# OAuth flow: Keycloak -> Backend (3000) -> Frontend (5173)
# Local development: http://localhost:3000
# Docker: http://localhost:3000
# Production: https://your-domain.com
BETTER_AUTH_URL=http://localhost:3000

# Enable email/password authentication on the frontend
# Set to "false" to disable email/password login (e.g., when using SSO only)
# Default: true
PUBLIC_EMAIL_PASSWORD_ENABLED=true

# ════════════════════════════════════════════════════════════════════════════
# CORS CONFIGURATION
# ════════════════════════════════════════════════════════════════════════════

# CORS origin [REQUIRED]
# The frontend URL that's allowed to make API requests
# Local development: http://localhost:5173
# Production: https://your-domain.com
CORS_ORIGIN=http://localhost:5173

# ════════════════════════════════════════════════════════════════════════════
# KEYCLOAK OIDC CONFIGURATION (OPTIONAL)
# ════════════════════════════════════════════════════════════════════════════

# Enable Keycloak SSO on the frontend (shows "Sign in with SSO" button)
# Set to "true" when Keycloak is configured on the server
PUBLIC_KEYCLOAK_ENABLED=false

# Keycloak base URL
# Format: https://your-keycloak-domain
# Example: https://keycloak.example.com
# KEYCLOAK_URL=https://keycloak.example.com

# Keycloak realm name
# Example: myrealm
# KEYCLOAK_REALM=myrealm

# Keycloak client ID for OIDC authentication
# Create a client in your Keycloak realm to get this value
# KEYCLOAK_CLIENT_ID=your-keycloak-client-id

# Keycloak client secret for OIDC authentication
# Create a confidential client in Keycloak to get this value
# KEYCLOAK_CLIENT_SECRET=your-keycloak-client-secret

# Keycloak issuer URL (optional, will be constructed from KEYCLOAK_URL and KEYCLOAK_REALM if not provided)
# Format: https://your-keycloak-domain/realms/your-realm
# Example: https://keycloak.example.com/realms/myrealm
# KEYCLOAK_ISSUER=https://keycloak.example.com/realms/myrealm

# Note: At minimum, KEYCLOAK_URL, KEYCLOAK_REALM, KEYCLOAK_CLIENT_ID, and KEYCLOAK_CLIENT_SECRET must be set

# ════════════════════════════════════════════════════════════════════════════
# AI PROVIDER SELECTION
# ════════════════════════════════════════════════════════════════════════════

# Primary AI provider selection
# Can be a single provider or comma-separated fallback chain
#
# Examples:
#   AI_PROVIDER=openai                    # Use OpenAI only
#   AI_PROVIDER=anthropic                  # Use Anthropic only
#   AI_PROVIDER=google                     # Use Google only
#   AI_PROVIDER=groq                       # Use Groq only
#   AI_PROVIDER=ollama                     # Use Ollama (local AI, no API key needed)
#   AI_PROVIDER=openai,anthropic,groq      # Fallback chain (try OpenAI, then Anthropic, then Groq)
#
# If not set, the provider will be auto-selected based on available API keys
AI_PROVIDER=openai

# Default AI model (used when provider-specific model is not set)
# Examples: "gpt-4o-mini", "claude-3-5-sonnet-20241022", "gemini-2.5-flash"
# AI_MODEL=gpt-4o-mini

# ════════════════════════════════════════════════════════════════════════════
# OPENAI CONFIGURATION (including OpenAI-compatible APIs)
# ════════════════════════════════════════════════════════════════════════════

# OpenAI API key (Required for OpenAI provider)
# Get your key from: https://platform.openai.com/api-keys
# Format: sk-...
OPENAI_API_KEY=your-openai-api-key-here

# OpenAI model selection (Optional)
# Defaults to gpt-4o-mini if not specified
# Options: gpt-4o-mini (fast/cheap), gpt-4o (balanced), o1-mini (reasoning), o1-preview (advanced)
# For Z.AI: glm-4.7
OPENAI_MODEL=gpt-4o-mini

# Custom OpenAI base URL (Optional)
# For OpenAI-compatible APIs like Z.AI
# Defaults to https://api.openai.com/v1
# Z.AI example: https://api.z.ai/api/coding/paas/v4
OPENAI_BASE_URL=https://api.openai.com/v1

# OpenAI organization ID (Optional)
# For org-level billing
# Find it at: https://platform.openai.com/account/org-settings
# OPENAI_ORGANIZATION=org-your-organization-id

# ════════════════════════════════════════════════════════════════════════════
# ANTHROPIC CONFIGURATION
# ════════════════════════════════════════════════════════════════════════════

# Anthropic API key (Required for Anthropic provider)
# Get your key from: https://console.anthropic.com/
# Format: sk-ant-...
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Anthropic model selection (Optional)
# Defaults to claude-3-5-sonnet-20241022 if not specified
# Options: claude-3-5-sonnet-20241022 (balanced), claude-3-5-haiku-20241022 (fast/cheap), claude-3-opus-20240229 (most capable)
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Custom Anthropic base URL (Optional)
# Defaults to https://api.anthropic.com
# ANTHROPIC_BASE_URL=https://api.anthropic.com

# Anthropic API version (Optional)
# Defaults to latest if not specified
# ANTHROPIC_VERSION=2023-06-01

# ════════════════════════════════════════════════════════════════════════════
# GOOGLE CONFIGURATION
# ════════════════════════════════════════════════════════════════════════════

# Google Generative AI API key (Required for Google provider)
# Get your key from: https://aistudio.google.com/app/apikey
# Format: AIza...
# GOOGLE_GENERATIVE_AI_API_KEY=your-google-api-key-here

# Alternative Google API key (Also accepted for backward compatibility)
# GOOGLE_API_KEY=your-google-api-key-here

# Google model selection (Optional)
# Defaults to gemini-2.5-flash if not specified
# Options: gemini-2.5-flash (fast/cheap), gemini-2.5-pro (more capable)
# GOOGLE_MODEL=gemini-2.5-flash

# ════════════════════════════════════════════════════════════════════════════
# GROQ CONFIGURATION
# ════════════════════════════════════════════════════════════════════════════

# Groq API key (Required for Groq provider)
# Get your key from: https://console.groq.com/keys
# Format: gsk_...
# GROQ_API_KEY=gsk-your-groq-api-key-here

# Groq model selection (Optional)
# Defaults to llama-3.3-70b-versatile if not specified
# Options: llama-3.3-70b-versatile (latest), llama-3.1-70b-versatile, mixtral-8x7b-32768
# GROQ_MODEL=llama-3.3-70b-versatile

# Custom Groq base URL (Optional)
# Defaults to https://api.groq.com/openai/v1
# GROQ_BASE_URL=https://api.groq.com/openai/v1

# ════════════════════════════════════════════════════════════════════════════
# OLLAMA CONFIGURATION (Local AI)
# ════════════════════════════════════════════════════════════════════════════

# Ollama runs locally, so no API key is required
# Make sure Ollama is running and the model is pulled
# Get Ollama from: https://ollama.com/
# Install models: ollama pull llama3.2

# Ollama model selection (Optional)
# Defaults to llama3.2 if not specified
# Options: llama3.2, llama3.1, mistral, codellama, gemma2, etc.
# OLLAMA_MODEL=llama3.2

# Ollama server URL (Optional)
# Defaults to http://localhost:11434/v1
# For Docker with host Ollama: http://host.docker.internal:11434
# OLLAMA_BASE_URL=http://localhost:11434/v1

# ════════════════════════════════════════════════════════════════════════════
# QUICK START EXAMPLES
# ════════════════════════════════════════════════════════════════════════════

# Example 1: Use Z.AI (OpenAI-compatible)
# AI_PROVIDER=openai
# OPENAI_API_KEY=your-z-ai-api-key
# OPENAI_BASE_URL=https://api.z.ai/api/coding/paas/v4
# OPENAI_MODEL=glm-4.7

# Example 2: Use OpenAI (Official)
# AI_PROVIDER=openai
# OPENAI_API_KEY=sk-...

# Example 3: Use Anthropic with Haiku (Fast & Cheap)
# AI_PROVIDER=anthropic
# ANTHROPIC_API_KEY=sk-ant-...
# ANTHROPIC_MODEL=claude-3-5-haiku-20241022

# Example 4: Fallback Chain for High Availability
# AI_PROVIDER=openai,anthropic,groq
# OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=sk-ant-...
# GROQ_API_KEY=gsk-...

# Example 5: Local AI (Zero Cost, Privacy-First)
# AI_PROVIDER=ollama
# OLLAMA_MODEL=llama3.2

# ════════════════════════════════════════════════════════════════════════════
# SETUP INSTRUCTIONS
# ════════════════════════════════════════════════════════════════════════════

# 1. Copy this file to .env:
#    cp .env.example .env
#
# 2. Fill in the required values:
#    - DATABASE_URL: Your PostgreSQL connection string
#    - BETTER_AUTH_SECRET: Generate a secure secret (min 32 chars)
#    - BETTER_AUTH_URL: Your application URL
#    - CORS_ORIGIN: Your frontend URL
#
# 3. Configure at least ONE AI provider:
#    - For cloud providers: Get API key and set AI_PROVIDER
#    - For local AI: Install Ollama, pull a model, set AI_PROVIDER=ollama
#
# 4. Start the application:
#    - Local development: bun run dev
#    - Docker: docker compose up
#
# ════════════════════════════════════════════════════════════════════════════
# SECURITY NOTES
# ════════════════════════════════════════════════════════════════════════════

# ⚠️  NEVER commit your .env file to version control
# ⚠️  NEVER share your API keys or secrets
# ⚠️  Use different API keys for development and production
# ⚠️  Rotate your API keys regularly
# ⚠️  Keep your BETTER_AUTH_SECRET secure and unpredictable
#
# ════════════════════════════════════════════════════════════════════════════
